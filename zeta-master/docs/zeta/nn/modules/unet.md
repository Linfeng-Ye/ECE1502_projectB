# Module Name: Unet

`Unet` is a convolutional neural network architecture predominantly used for biomedical image segmentation. The architecture comprises two primary pathways: downsampling and upsampling, followed by an output convolution. Due to its U-shape, the architecture is named `U-Net`. Its symmetric architecture ensures that the context (from downsampling) and the localization (from upsampling) are captured effectively.

## Overview

- **Downsampling**: This captures the context of the input image, compressing the spatial dimensions and expanding the depth (number of channels). This is typically done using convolutional and pooling layers.

- **Upsampling**: This uses the context information to localize and segment the image, expanding its spatial dimensions to match the original input dimensions. Upsampling can be done using transposed convolutions or bilinear interpolations based on the given setting.

- **Skip connections**: These connections are essential in U-Net as they connect layers from the downsampling path to the corresponding layers in the upsampling path. This helps in recovering the fine-grained details lost during downsampling.

- **Output**: The final layer produces the segmented image, usually with channels corresponding to each class or segment.

## Class Definition:

```python
class Unet(nn.Module):
```

### Parameters:

| Parameter  | Data Type | Description                                                                                                   |
|------------|-----------|---------------------------------------------------------------------------------------------------------------|
| n_channels | int       | Number of input channels.                                                                                     |
| n_classes  | int       | Number of output channels (typically, number of segmentation classes).                                         |
| bilinear   | bool      | Determines the method of upsampling. If True, uses bilinear interpolation; otherwise, uses transposed convolution. Default is False. |

### Methods:

#### 1. `forward(x: torch.Tensor) -> torch.Tensor`:

The forward method defines the flow of input through the U-Net architecture. 

**Parameters**:

- `x (torch.Tensor)`: Input tensor.

**Returns**:

- `torch.Tensor`: Output segmented image.

#### 2. `use_checkpointing() -> None`:

This method enables gradient checkpointing for the U-Net model, which is a technique to reduce memory consumption during training by trading off computation time.

### Usage Example:

```python
import torch

from zeta.nn import Unet  # Update `<path_to_module>` to your specific path

# Initialize the U-Net model
model = Unet(n_channels=1, n_classes=2)

# Random input tensor with dimensions [batch_size, channels, height, width]
x = torch.randn(1, 1, 572, 572)

# Forward pass through the model
y = model(x)

# Output
print(f"Input shape: {x.shape}")
print(f"Output shape: {y.shape}")
```

## Architecture Flow:

1. **Input**: Takes an image tensor as input with `n_channels`.

2. **Downsampling Path**:
   - Double convolution on the input.
   - Four downsampling steps with double convolutions. 
   - The depth of the feature maps increases, while the spatial dimensions decrease.

3. **Upsampling Path**:
   - Four upsampling steps where the feature maps from the downsampling path are concatenated and followed by up convolutions.
   - The spatial dimensions increase, moving closer to the original input size.

4. **Output**: 
   - A final output convolution to map the feature maps to desired `n_classes`.

5. **Checkpointing (optional)**:
   - If memory optimization during training is required, `use_checkpointing` can be invoked. This will enable gradient checkpointing to save memory during the backward pass.

## Additional Tips:

- The bilinear interpolation mode of upsampling is typically faster and consumes less memory than the transposed convolution method. However, it might not always provide the same level of detail in the upsampled feature maps.

- Gradient checkpointing in `use_checkpointing` is useful for models with deep architectures or when the available GPU memory is limited. Remember, while this method saves memory, it also requires additional computation during the backward pass.

- Ensure the input dimensions are appropriate for the U-Net model. Given the number of downsampling and upsampling layers in the architecture, certain input dimensions might not produce the expected output dimensions.

## References and Resources:

- Ronneberger, O., Fischer, P., & Brox, T. (2015). [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/abs/1505.04597). In International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI).

- PyTorch Official Documentation on [checkpointing](https://pytorch.org/docs/stable/checkpoint.html).

**Note**: It's essential to understand that while the U-Net architecture is provided, the definitions and implementations of `DoubleConv`, `Down`, `Up`, and `OutConv` are not provided in the code. Ensure you have these components documented or explained as well if they are part of your library or module.